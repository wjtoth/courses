\documentclass[letterpaper,12pt,oneside,onecolumn]{article}
\usepackage[margin=1in, bottom=1in, top=1in]{geometry} %1 inch margins
\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{theorem}
\usepackage{tikz}
\usepackage{tkz-berge}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
 
\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}


\newenvironment{proof}{{\bf Proof:  }}{\hfill\rule{2mm}{2mm}}
\newenvironment{proofof}[1]{{\bf Proof of #1:  }}{\hfill\rule{2mm}{2mm}}
\newenvironment{proofofnobox}[1]{{\bf#1:  }}{}\newenvironment{example}{{\bf Example:  }}{\hfill\rule{2mm}{2mm}}

%\renewcommand{\thesection}{\lecnum.\arabic{section}}
%\renewcommand{\theequation}{\thesection.\arabic{equation}}
%\renewcommand{\thefigure}{\thesection.\arabic{figure}}

\newtheorem{fact}{Fact}[section]
\newtheorem{lemma}[fact]{Lemma}
\newtheorem{theorem}[fact]{Theorem}
\newtheorem{definition}[fact]{Definition}
\newtheorem{corollary}[fact]{Corollary}
\newtheorem{proposition}[fact]{Proposition}
\newtheorem{claim}[fact]{Claim}
\newtheorem{exercise}[fact]{Exercise}
\newtheorem{note}[fact]{Note}
\newtheorem{conjecture}[fact]{Conjecture}

\newcommand{\size}[1]{\ensuremath{\left|#1\right|}}
\newcommand{\ceil}[1]{\ensuremath{\left\lceil#1\right\rceil}}
\newcommand{\floor}[1]{\ensuremath{\left\lfloor#1\right\rfloor}}

%END MACROS
%Page style
\pagestyle{fancy}

\listfiles

\raggedbottom

\lhead{2017-01-26}
\rhead{William Justin Toth CO750-Approximation Algorithms Lecture n} %CHANGE n to ASSIGNMENT NUMBER ijk TO COURSE CODE
\renewcommand{\headrulewidth}{1pt} %heading underlined
%\renewcommand{\baselinestretch}{1.2} % 1.2 line spacing for legibility (optional)

\begin{document}
\section*{Integrality Gap}
\paragraph{}
Let $P$ be an optimization problem, and suppose that there exists an integer programming formulation for $P$. Denote by $OPT(I)$ the objective function value of an optimal solution to an instance $I$ of $P$. Denote by $OPT_f(I)$ the objective function value of the Linear Programming relaxation of the IP formulation of $I$.
\paragraph{}
The integrality gap of the formulation is
$$\inf_{I \in P} \frac{OPT(I)}{OPT_f(I)}$$
for maximization problems, and
$$\sup_{I \in P} \frac{OPT(I)}{OPT_f(I)}$$
for minimization problems.
\section{Iterative Rounding}
\paragraph{}  Recall the linear programming formulation $LP$ for Generalized Steiner Network (GSN):
\begin{align*}
\min &\sum_e c_e x_e \\
\text{s.t.} x(\delta(S)) &\geq f(S) &\forall S \subseteq V\\
x&\geq 0
\end{align*}
where $f(S) = \max_{u \in S, v \not\in S} r(u,v).$
\paragraph{}
A function $f: 2^V \rightarrow \Z$ is called weakly-supermodular (wsm) if
\begin{enumerate}
\item $f(V) = 0$ and
\item For all $A,B \subseteq V$ at least one of the following holds
\begin{enumerate}
\item $f(A) + f(B) \leq f(A\backslash B) + f(B \backslash A)$ or
\item $f(A) + f(B) \leq f(A\cup B) + f(A\cap B).$
\end{enumerate}
\end{enumerate}
\begin{proposition}
If $f$ is a proper function then $f$ is wsm.
\end{proposition}
\paragraph{}
Recall that an extreme point solution (xps) to an LP is a feasible solution which cannot be written as a convex combination of other feasible solutions.
\begin{proposition}
An optimal xps of $LP$ for GSN can be computed in polynomial time.
\end{proposition}
\begin{theorem}
For any wsm function $f$, any xps to $LP$ satisfies $x_e \geq \frac{1}{2}$ for at least one $e \in E$.
\end{theorem}
\paragraph{}
The previous theorem yields a natural algorithm for GSN:
\begin{enumerate}
\item Set $H= \emptyset$, and $f' = f$.
\item While $f' \neq 0$
\begin{enumerate}
\item Find an optimal xps for $LP$ with $f'$
\item For all $e$ such that $x_e \geq \frac{1}{2}$, include $\ceil{x_e}$ copies of $e$ in $H$
\item Update $f'$: for all $S\subseteq V$, set $f(S) = \max \{f(S)-|\delta_H(S)|, 0\}$.
\end{enumerate}
\item Output $H$.
\end{enumerate}
\begin{lemma}
Let $H$ be a (multi)subgraph of $G$. If $f: 2^V \rightarrow \Z_+$ is wsm then $f'(S) = \max \{ f(S) - |\delta_H(S)|, 0\}$ is wsm.
\end{lemma}
\begin{lemma}
We can solve the $LP$ relaxation for GSN in polynomial time at any iteration of the algorithm for instances of GSN.
\end{lemma}
\begin{theorem}
The solution $H$ output by the algorithm has cost at most $2$ times the cost of the optimal solution to the $LP$ relaxation.
\end{theorem}
\begin{proof}
Proceed by induction on the number of iterations. If the algorithm only requires one iteration then the result is immediate. Otherwise let $x$ be an optimal xps in the first iteration. Let $\hat{x}$ be defined as
$$ \hat{x}_e = \begin{cases} 1, &\forall e, x_e \geq \frac{1}{2} \\
0, &\text{otherwise}\end{cases}$$
Let $H^1$ be the set of edges taken in the first iteration. Then $c(H^1) \leq 2c(\hat{x})$. Let $f'$ be the requirement function after the first iteration and let $H'$ be the set of edges picked by the algorithm in all subsequent iterations. 
\paragraph{}
The key observation: $(x-\hat{x})$ is a feasible solution for $f'$. So by induction $c(H') \leq 2c(x-\hat{x})$. In total
$$c(H^1 \cup H') \leq 2c(\hat{x}) + 2c(x-\hat{x}) \leq 2c(x).$$
\end{proof}
\paragraph{}
An xps $x$ of $LP$ satisfies $m = |E|$ linearly independent inequalities with equality (tight). In our analysis to follow we will make the simplifying assumption that $x_e > 0$ for all $e\in E$. We may assume this by removing all $e$ such that $x_e = 0$. For a set $S$ we will denote by $\chi(S)$ the incidence vector of $S$.
\paragraph{}
A collection $\cL$ of subsets of $V$ is a \textit{laminar} family if no two sets in this collection ``crosses". By crosses we mean for all $A, B \in \cL$, we have $A\cap B \neq \emptyset$ and either $A\backslash B \neq \emptyset$ or $B\backslash A \neq \emptyset$.
\begin{theorem}
For any xps $x$ to $LP$ there is a collection of $m$ tight sets such that their incidence vectors are linearly independent, and the collection is a laminar family.
\end{theorem}
\begin{proof}
To follow in next lecture.
\end{proof}
\end{document}
